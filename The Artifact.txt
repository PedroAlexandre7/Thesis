Chapter 3: The Artifact: A Declarative IoT Dimensioning Model

3.1 Overview and Design Philosophy

This chapter details the design and implementation of the thesis artifact: a Declarative Excel-based IoT Dimensioning Framework.

As outlined in Chapter 1, the primary objective of this work is to bridge the gap between rigid, "black-box" professional simulators and fragile, ad-hoc spreadsheets. While standard spreadsheets are accessible, they often suffer from scalability issues; adding a new variable (e.g., a new planning year or a new vertical) typically requires manual restructuring of the entire workbook, leading to errors and auditing difficulties (Caulkins et al., 2007).

To address Research Question 4 (How can the complex process of public IoT network dimensioning be simplified...?), the proposed artifact adopts a Meta-Programming approach. The core design philosophy is the strict separation of the definition of the model from its instantiation.

Instead of hard-coding logic into specific cells, the user defines the structure of the desired analysis—such as the planning horizon, geographical segmentation, and service taxonomy—in a centralized configuration interface. An automation engine (implemented in VBA) then interprets these high-level instructions to dynamically construct the necessary analysis sheets. This architecture transforms the workbook from a static calculation file into a dynamic modeling environment, ensuring that the tool remains:

Scalable: Capable of handling varying numbers of regions or verticals without structural redesign.

Transparent: Ensuring that all dimensioning assumptions are explicit and auditable.

Assumption-Driven: Facilitating rapid "first-pass" dimensioning by allowing planners to toggle key constraints (e.g., traffic concurrency, coverage thresholds) centrally.

3.2 System Architecture

The artifact functions as a layered application built within the Microsoft Excel environment. It is architected around three distinct layers, as illustrated in the system design:

3.2.1 The Configuration Layer (The "Blueprints")
The entry point for the planner is the Model Configurator sheet. This sheet acts as a domain-specific language (DSL) where the user defines the "Instructions" for the model. As seen in the tool's interface, this layer accepts the following abstract commands:

Years: Defines the temporal scope (e.g., 2023, 2025, 2030). This instruction controls the time-dimension expansion, automatically replicating columns or sheets to accommodate the defined planning horizon.

Title: Groups data by logical entities (e.g., "Regions"). This instruction triggers the iterative generation of tables, ensuring that a separate analysis block is created for every defined entity (e.g., creating a table for "Central Coast", "Cessnock", etc.).

Header: Defines the static horizontal structure of a table. It maps to specific row inputs (e.g., "Throughput", "Devices", "Cost") that form the column headers of the generated analysis tables.

Column: Defines the vertical structure or data drivers. This instruction pulls lists from input sheets (e.g., the list of 15 "Verticals" or 10 "Base Station Types") to dynamically determine the height of the generated tables, ensuring the model adapts automatically if items are added to or removed from the source lists.

Output: Designates the target sheet for the analysis tables. In the logic of the DSL, this command functions as a block terminator; it signals that the preceding collection of instructions (headers, columns, etc.) constitutes a complete set and directs the engine to render the results in the specified worksheet.

3.2.2 The Automation Layer (The "Engine")
The logic core is a VBA-based automation backend that reads the Configuration Layer and algorithmically builds the spreadsheet. This layer abstracts the complexity of Excel's object model by separating state (Data Transfer Objects) from execution logic (Procedural Modules).

3.2.2.1 Data Transfer Objects (DTOs)
To manage the state of the model during the construction phase, the artifact utilizes two primary custom classes. These classes function as Data Transfer Objects—they encapsulate properties and metadata but delegate execution logic to the main engine.

InputData Class (The Input Abstraction):
This class acts as a sophisticated container for user-defined inputs. It stores the essential properties of a data block, such as the source Range, the assigned InstructionType (Years, Title, Header, Column), and spatial metadata like rowShift and columnShift. By encapsulating these properties into a standardized object, the class allows the automation engine to treat diverse inputs uniformly. It essentially holds the "blueprint" for a specific piece of data, defining where it comes from and how it should be positioned relative to others, without containing the logic to move the cells itself.

TableSetData Class (The Output Context):
Complementing the input abstraction, the TableSetData class functions as the state container for the output destination. When the engine encounters an Output instruction, it instantiates this object to hold the context for the subsequent generation process. It stores critical definition parameters such as the target Worksheet, the starting coordinates (firstRow, firstColumn), and boolean flags for operations like ClearData.

3.2.2.2 The Procedural Execution Loop (Main Module)
The orchestration of these objects is handled by the Main module, specifically the CreateTablesFromInput routine. This module contains the procedural logic that acts upon the DTOs described above.

The execution flow operates as a linear interpreter for the configuration DSL. The Main routine iterates through the instruction list, parsing each row into an InputData object. It accumulates these objects into collections until an Output command is detected. At this trigger point, the engine calls specialized subroutines—such as CreateTables, CreateHeadersAndColumns, and CopyCells. These subroutines consume the TableSetData and InputData objects as arguments, reading their properties to determine exactly where to paste ranges, how to adjust formula references, and how to format the destination cells. This architecture strictly separates the definition of the data (Classes) from the manipulation of the spreadsheet (Modules), resulting in a robust and auditable build process.

3.2.3 The Data Layer (The "Interface")
The Data Layer constitutes the interactive frontend of the framework, comprising the generated input and output sheets where the planner performs the dimensioning tasks. It is crucial to emphasize that the specific sheet structure described in this section is not intrinsic to the tool's code but is a product of the configuration defined in the Model Configurator. While the framework is agnostic to the specific use case, for the purpose of this thesis, the artifact has been instantiated with data representing an Australian Smart City network (e.g., Central Coast, Cessnock). This dataset serves as a validation case study, demonstrating how the generic template can be adapted to specific regional requirements. The user retains the flexibility to divide and analyze the network using different components or sections by simply modifying the configuration inputs.

3.2.3.1 Dimensions and Analysis Scope
The foundation of the model is built upon three primary dimensions that define the granularity and scope of the analysis. These sheets act as the coordinates for the calculation matrices:

Study Years: This sheet establishes the temporal horizon of the project (e.g., 2023, 2025). It is critical for analyzing the network dimensioning evolution over time, allowing the planner to ensure that the proposed infrastructure remains sufficient as demand grows. While this dimension also supports cost analysis, the primary focus is on technical validation throughout the project lifecycle.

Regions: Defines the spatial segmentation of the analysis.

Verticals_Sectors: Establishes the service taxonomy, categorizing the various use cases (e.g., "Utilities", "Public Safety") that will drive the network load.

3.2.3.2 Traffic Generation and Network Configuration
This section details the sheets that contain the core logic for calculating demand and defining the network supply. The workflow proceeds from traffic aggregation to infrastructure mapping:

Traffic Calculation (Throughput & Throughput Formulas & Network Parameters):
The quantification of network demand occurs in the Throughput sheet. This sheet acts as the primary input interface where the planner enters device counts and defines specific traffic attributes for each vertical (based on the taxonomy defined in Verticals_Sectors). The underlying structure and calculation logic - including the aggregation of traffic profiles - are defined in the Throughput Formulas template. This separation allows the model to enforce a consistent calculation methodology across different scenarios while providing a distinct interface for data entry. Global assumptions from Network Parameters (e.g., "Busy Hour Contention Ratio") are applied here to convert raw device counts into dimensioning-relevant metrics.

Infrastructure Definition (Base Stations Sites & Base Stations Profiles):
The technological capabilities of the network are defined here. Base Stations Sites serves as a catalog of the available technology types (e.g., "Standalone 5G", "LoRaWAN"), while Base Stations Profiles specifies the performance attributes of each type, such as maximum active users and downlink throughput.

Siting Logic (Sites per Region):
This sheet functions as the primary control variable for the dimensioning exercise. Here, a user-defined site distribution is mapped. This infrastructure layout does not necessarily reflect an existing deployment; rather, it allows the user to propose a baseline quantity of sites per region. The logic serves to feed the saturation analysis - by establishing a supply baseline, the model can later identify capacity gaps and calculate the remedial "Sites to Cover" in the output phase.

3.2.3.3 The Physics Engine: 
The Base Stations Parameters sheet operationalizes the radio frequency (RF) physics of the network. While the model's core dimensioning logic utilizes the fixed capacity thresholds defined in the Base Stations Profiles, this module was explicitly implemented to facilitate a comparative analysis. Its purpose is to contrast the pre-given capacity values (often based on static vendor specifications or high-level assumptions) against the mathematically accurate limits derived from first principles. By calculating capacity and coverage using rigorous physical models, this section allows for a critical study of the discrepancies between heuristic planning inputs and theoretical reality, demonstrating the potential of integrating mathematical precision into the dimensioning workflow. All parameters and constants utilized in these calculations are strictly grounded in the technical literature and standards (e.g., 3GPP TR 38.901). It operationalizes two critical theoretical models:

Shannon-Hartley Capacity: The sheet calculates the theoretical maximum throughput for each site type using the spectral efficiency formula. Inputs such as Bandwidth (MHz), MIMO layers, and Signal-to-Noise Ratio (SNR) are combined to derive the data rate limit ($C$), ensuring that the capacity values used in the dimensioning are grounded in physical reality rather than arbitrary estimates.

Link Budget and Path Loss: To validate coverage, the sheet implements a link budget calculation. It accounts for Transmit Power ($P_{tx}$), Antenna Gains ($G$), and Losses ($L$) to determine the Received Signal Power. Furthermore, it incorporates logarithmic path loss models (aligned with standard 3GPP propagation models) dependent on carrier frequency (e.g., 800 MHz vs. 26 GHz) and base station height. This allows the model to estimate the maximum effective radius of a cell, providing a "sanity check" to ensure that the number of sites proposed for capacity reasons is also sufficient to provide geographical coverage.

3.2.3.4 The Analytical Core: Output Formulas and Model Output
The synthesis of Demand and Supply occurs in the Output Formulas and Model Output sheets. These components represent the analytical core of the framework.

Output Formulas (The Template Engine): This sheet contains the master formulas that drive the final analysis. It utilizes advanced Excel functions such as LET and INDIRECT to create dynamic references. Instead of hard-linking to specific cells, the formulas dynamically search for data ranges based on the current "Year" and "Region" context. This design allows the automation engine to replicate these formulas across hundreds of generated tables without breaking references, a common failure point in static spreadsheets.

Model Output (The Dashboard): This is the destination sheet where the dimensioning results are aggregated. For every Region and Year, the model generates a table that compares the Total Demand (aggregated from all Verticals) against the Total Supply (sum of all Site capabilities). It calculates two critical metrics:

Saturation %: The ratio of Demand to Supply for both Active Users and Throughput. Values exceeding 100% highlight immediate functionality gaps.

Cost Analysis: Based on the "Sites to Cover" (the delta required to reduce saturation below 100%) and the "Cost per Site," the model estimates the financial investment required to close the gap.

3.3 Functional Components and Input Structure

The artifact organizes the dimensioning process into logical steps that align with the Traffic Theory principles discussed in Section 2.2.

3.3.1 Service Taxonomy (Verticals_Sectors)

Reflecting the "Verticals" approach advocated by the Municipal IoT Blueprint (Barkis et al., 2019), the model begins by defining the service taxonomy. The Verticals_Sectors sheet acts as the primary dimension for traffic generation. By categorizing services (e.g., "Utilities," "Public Safety"), the tool allows for granular traffic profiling, ensuring that low-bandwidth sensors are differentiated from high-bandwidth video streams.

3.3.2 Network Parameters and Traffic Engineering

The Network Parameters sheet serves as the repository for the global assumptions driving the capacity dimensioning. It translates the theoretical concepts of Erlang and Packet Switching into concrete inputs:

Busy Hour Contention Ratio: Defines the concentration of traffic during peak windows.

Headroom: Implements the "resiliency buffer" described in the State of the Art, allowing planners to set a safety margin (e.g., 20%) for emergency spikes.

3.3.3 Infrastructure Definition (Base Stations Sites & Profiles)

To support the technology-agnostic requirement (RQ1), the artifact separates the physical site counts from their technological capabilities.

Base Stations Sites: Captures the "Supply" side of the equation—how many physical locations are available or planned per region.

Base Stations Profiles: Defines the capability of each site type (e.g., "Standalone 5G - 3 Sectors" vs. "LoRaWAN Gateway"). This sheet includes critical dimensioning thresholds such as "Maximum Simultaneously Active Users" and "Maximum Throughput for Downlink," allowing the model to flag saturation based on either user density or data volume.

3.4 The Calculation Engine

The logical core of the artifact resides in the Throughput Formulas and Base Stations Parameters sheets. Here, the tool synthesizes the inputs to perform the actual dimensioning.

3.4.1 Throughput and Capacity Dimensioning

The model calculates the Aggregate Demand for every combination of Year, Region, and Vertical. It utilizes the formulas discussed in Section 2.3, multiplying the number of devices by their specific traffic profiles (throughput buckets) and applying the Busy Hour factor.

Simultaneously, it calculates Network Supply based on the site profiles. A key feature of the artifact, visualized in the Output Formulas sheet, is the automated comparison of Demand vs. Supply. The model calculates saturation percentages, highlighting functionality gaps where demand exceeds the "Capacity Limited" constraints of the network.

3.4.2 Coverage and Path Loss Validation

While the primary focus is capacity, the artifact includes a coverage validation module in Base Stations Parameters. As detailed in the State of the Art, rigorous ray-tracing is often infeasible for high-level planning. Therefore, this tool implements formula-based Path Loss calculations (aligned with 3GPP TR 38.901 concepts) directly within the spreadsheet cells.

By defining parameters such as Transmit Power, Antenna Gains, and Frequency (e.g., 800 MHz vs. 26 GHz), the model estimates the maximum cell radius. This allows the user to sanity-check if the number of sites proposed in the "Capacity" step is sufficient to provide physical signal coverage across the target region's area.

3.5 Conclusion

The artifact presented is not merely a calculator but a Declarative Modeling Environment. By leveraging VBA to automate the structural management of the spreadsheet (CreateTablesFromInput), it resolves the tension between the flexibility required for strategic planning and the robustness required for engineering. It successfully operationalizes the theoretical constraints of Smart City IoT—from vertical taxonomies to link budgets—into a usable, auditable, and scalable tool.